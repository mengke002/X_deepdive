#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤åˆ©ç³»ç»Ÿæ¨¡å— (Flywheel System)
åŸºäº ANALYSIS_MINING_PLAN.md é˜¶æ®µä¸‰è®¾è®¡

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä¿¡æ¯æ—¶å·®ä¸æˆªæµ (Smart Reply & Arbitrage)
   - çˆ†æ¬¾æ—©æœŸæ£€æµ‹
   - æ™ºèƒ½å›å¤è‰ç¨¿ç”Ÿæˆ
2. è‡ªåŠ¨åŒ–è¾…åŠ©åˆ›ä½œ (Content Co-pilot)
   - çŸ¥è¯†åº“å¤ç”¨
   - å†™ä½œè¾…åŠ©
"""

import os
import json
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any
from collections import defaultdict

import pandas as pd
import numpy as np

from .llm_client import get_llm_client
from .analysis_db import get_analysis_db_adapter
from .prompts import PROMPT_SMART_REPLY

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class VelocityDetector:
    """
    çˆ†æ¬¾æ—©æœŸæ£€æµ‹å™¨
    é€šè¿‡åˆ†ææ¨æ–‡çš„äº’åŠ¨å¢é€Ÿæ¥è¯†åˆ«æ½œåœ¨çˆ†æ¬¾
    """
    
    def __init__(self, velocity_threshold_percentile: float = 95):
        """
        Args:
            velocity_threshold_percentile: å¢é€Ÿé˜ˆå€¼çš„ç™¾åˆ†ä½æ•°
        """
        self.velocity_threshold_percentile = velocity_threshold_percentile
        self.historical_velocities = []  # å­˜å‚¨å†å²å¢é€Ÿæ•°æ®ç”¨äºè®¡ç®—é˜ˆå€¼
        
    def calculate_velocity(self, 
                          current_stats: Dict[str, int], 
                          previous_stats: Dict[str, int],
                          time_delta_minutes: float) -> Dict[str, float]:
        """
        è®¡ç®—äº’åŠ¨å¢é€Ÿ
        
        Args:
            current_stats: å½“å‰ç»Ÿè®¡æ•°æ® {likes, replies, retweets, views}
            previous_stats: ä¸Šæ¬¡ç»Ÿè®¡æ•°æ®
            time_delta_minutes: æ—¶é—´å·®ï¼ˆåˆ†é’Ÿï¼‰
            
        Returns:
            å„æŒ‡æ ‡çš„æ¯åˆ†é’Ÿå¢é€Ÿ
        """
        if time_delta_minutes <= 0:
            return {}
            
        velocities = {}
        for key in ['likes', 'replies', 'retweets', 'views']:
            current = current_stats.get(key, 0)
            previous = previous_stats.get(key, 0)
            delta = current - previous
            velocity = delta / time_delta_minutes
            velocities[f'{key}_velocity'] = velocity
            
        # è®¡ç®—ç»¼åˆå¢é€Ÿè¯„åˆ†
        # æƒé‡ï¼šreplies > retweets > likes > views
        weights = {'likes': 1.0, 'replies': 3.0, 'retweets': 2.0, 'views': 0.1}
        weighted_velocity = sum(
            velocities.get(f'{k}_velocity', 0) * w 
            for k, w in weights.items()
        )
        velocities['weighted_velocity'] = weighted_velocity
        
        return velocities
    
    def is_velocity_spike(self, velocity: float) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦æ˜¯å¢é€Ÿå¼‚å¸¸ï¼ˆæ½œåœ¨çˆ†æ¬¾ï¼‰
        """
        if not self.historical_velocities:
            return velocity > 0  # æ²¡æœ‰å†å²æ•°æ®æ—¶ï¼Œä»»ä½•æ­£å¢é€Ÿéƒ½æ ‡è®°
            
        threshold = np.percentile(self.historical_velocities, self.velocity_threshold_percentile)
        return velocity > threshold
    
    def update_historical(self, velocity: float):
        """æ›´æ–°å†å²å¢é€Ÿæ•°æ®"""
        self.historical_velocities.append(velocity)
        # ä¿æŒæœ€è¿‘1000æ¡è®°å½•
        if len(self.historical_velocities) > 1000:
            self.historical_velocities = self.historical_velocities[-1000:]


class SmartReplyGenerator:
    """
    æ™ºèƒ½æˆªæµå›å¤ç”Ÿæˆå™¨
    å½“æ£€æµ‹åˆ°æ½œåœ¨çˆ†æ¬¾æ—¶ï¼Œç”Ÿæˆé«˜è´¨é‡å›å¤è‰ç¨¿
    """
    
    def __init__(self):
        self.llm_client = get_llm_client()
        self.analysis_db = get_analysis_db_adapter()
        
    def generate_reply_draft(self, 
                            tweet_text: str, 
                            tweet_author: str,
                            tweet_stats: Dict[str, int],
                            author_context: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """
        ç”Ÿæˆæ™ºèƒ½å›å¤è‰ç¨¿
        
        Args:
            tweet_text: åŸæ¨æ–‡å†…å®¹
            tweet_author: åŸæ¨æ–‡ä½œè€…
            tweet_stats: æ¨æ–‡ç»Ÿè®¡æ•°æ®
            author_context: ä½œè€…èƒŒæ™¯ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            å›å¤è‰ç¨¿åŠç›¸å…³å…ƒæ•°æ®
        """
        if not self.llm_client:
            logger.error("LLM Client æœªåˆå§‹åŒ–")
            return None
            
        # æ„å»ºè¾“å…¥æ•°æ®
        input_data = json.dumps({
            "original_tweet": {
                "text": tweet_text[:500],  # é™åˆ¶é•¿åº¦
                "author": tweet_author,
                "stats": tweet_stats
            },
            "author_context": author_context or "æœªçŸ¥",
            "goal": "åœ¨è¿™æ¡æ­£åœ¨å¿«é€Ÿä¼ æ’­çš„æ¨æ–‡ä¸‹ç•™ä¸‹é«˜ä»·å€¼è¯„è®ºï¼Œå»ºç«‹ä¸“ä¸šå½¢è±¡"
        }, ensure_ascii=False)
        
        prompt = PROMPT_SMART_REPLY.format(input_data=input_data)
        
        try:
            response = self.llm_client.call_fast_model(prompt)
            
            if response['success']:
                content = response['content']
                content = content.replace('```json', '').replace('```', '').strip()
                
                try:
                    result = json.loads(content)
                    result['model_used'] = response.get('model')
                    result['generated_at'] = datetime.now().isoformat()
                    return result
                except json.JSONDecodeError:
                    logger.error(f"JSON è§£æå¤±è´¥: {content[:100]}...")
                    return None
            else:
                logger.error(f"LLM è°ƒç”¨å¤±è´¥: {response.get('error')}")
                return None
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›å¤è‰ç¨¿æ—¶å‡ºé”™: {e}")
            return None
    
    def save_candidate(self, 
                      tweet_id: str,
                      author_username: str,
                      detected_signal: str,
                      tweet_text: str,
                      reply_result: Dict[str, Any]):
        """ä¿å­˜æˆªæµå€™é€‰åˆ°æ•°æ®åº“"""
        if not self.analysis_db:
            logger.warning("åˆ†ææ•°æ®åº“æœªé…ç½®ï¼Œè·³è¿‡ä¿å­˜")
            return
            
        candidate = {
            'target_tweet_id': tweet_id,
            'author_username': author_username,
            'detected_signal': detected_signal,
            'tweet_text': tweet_text,
            'draft_reply_text': reply_result.get('reply_draft', '')
        }
        
        self.analysis_db.save_smart_reply_candidates([candidate])
        logger.info(f"å·²ä¿å­˜æˆªæµå€™é€‰: {tweet_id}")


class ContentCopilot:
    """
    å†…å®¹è¾…åŠ©åˆ›ä½œç³»ç»Ÿ
    åŸºäºçŸ¥è¯†åº“å¤ç”¨å’Œå†å²é«˜ä»·å€¼å†…å®¹è¾…åŠ©æ–°å†…å®¹åˆ›ä½œ
    """
    
    def __init__(self, knowledge_dir: str = 'output/llm_insights'):
        self.knowledge_dir = knowledge_dir
        self.content_blueprints = []
        self.thread_templates = []
        self._load_knowledge_base()
        
    def _load_knowledge_base(self):
        """åŠ è½½çŸ¥è¯†åº“"""
        # åŠ è½½çˆ†æ¬¾å†…å®¹è“å›¾
        blueprints_file = os.path.join(self.knowledge_dir, 'Content_Blueprints.json')
        if os.path.exists(blueprints_file):
            with open(blueprints_file, 'r', encoding='utf-8') as f:
                self.content_blueprints = json.load(f)
            logger.info(f"åŠ è½½äº† {len(self.content_blueprints)} ä¸ªå†…å®¹è“å›¾")
        
        # åŠ è½½ Thread æ¨¡æ¿
        threads_file = os.path.join(self.knowledge_dir, 'Thread_Blueprints.json')
        if os.path.exists(threads_file):
            with open(threads_file, 'r', encoding='utf-8') as f:
                self.thread_templates = json.load(f)
            logger.info(f"åŠ è½½äº† {len(self.thread_templates)} ä¸ª Thread æ¨¡æ¿")
    
    def find_similar_content(self, 
                            topic: str, 
                            content_type: str = 'any',
                            top_k: int = 5) -> List[Dict]:
        """
        æŸ¥æ‰¾ç›¸ä¼¼çš„é«˜ä»·å€¼å†…å®¹ä½œä¸ºå‚è€ƒ
        
        Args:
            topic: ä¸»é¢˜å…³é”®è¯
            content_type: å†…å®¹ç±»å‹ ('thread', 'single', 'any')
            top_k: è¿”å›æ•°é‡
            
        Returns:
            ç›¸å…³å†…å®¹åˆ—è¡¨
        """
        results = []
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼ˆåç»­å¯ä»¥å‡çº§ä¸ºå‘é‡æ£€ç´¢ï¼‰
        topic_lower = topic.lower()
        
        for bp in self.content_blueprints:
            original_text = bp.get('original_text', '').lower()
            why_viral = bp.get('why_viral', '').lower()
            
            # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
            score = 0
            if topic_lower in original_text:
                score += 2
            if topic_lower in why_viral:
                score += 1
                
            if score > 0:
                results.append({
                    'type': 'blueprint',
                    'score': score,
                    'content': bp
                })
        
        # æ’åºå¹¶è¿”å› top_k
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:top_k]
    
    def get_writing_suggestions(self, topic: str) -> Dict[str, Any]:
        """
        è·å–å†™ä½œå»ºè®®
        
        Args:
            topic: è¦å†™çš„ä¸»é¢˜
            
        Returns:
            å†™ä½œå»ºè®®å’Œå‚è€ƒèµ„æ–™
        """
        similar_content = self.find_similar_content(topic)
        
        suggestions = {
            'topic': topic,
            'similar_successful_content': similar_content,
            'hook_suggestions': [],
            'structure_suggestions': [],
            'cta_suggestions': []
        }
        
        # ä»ç›¸ä¼¼å†…å®¹ä¸­æå–å»ºè®®
        for item in similar_content:
            bp = item.get('content', {})
            
            hook = bp.get('hook_style', {})
            if hook:
                suggestions['hook_suggestions'].append({
                    'type': hook.get('type'),
                    'example': hook.get('text')
                })
            
            body = bp.get('body_structure')
            if body:
                suggestions['structure_suggestions'].append(body)
                
            cta = bp.get('call_to_action', {})
            if cta:
                suggestions['cta_suggestions'].append({
                    'type': cta.get('type'),
                    'example': cta.get('text')
                })
        
        # å»é‡
        suggestions['structure_suggestions'] = list(set(suggestions['structure_suggestions']))
        
        return suggestions
    
    def get_thread_template(self, style: str = 'any') -> Optional[Dict]:
        """
        è·å– Thread å†™ä½œæ¨¡æ¿
        
        Args:
            style: æ¨¡æ¿é£æ ¼ ('educational', 'story', 'listicle', 'any')
            
        Returns:
            Thread æ¨¡æ¿
        """
        if not self.thread_templates:
            return None
            
        if style == 'any':
            # éšæœºè¿”å›ä¸€ä¸ª
            import random
            return random.choice(self.thread_templates)
        
        # æŒ‰é£æ ¼ç­›é€‰
        for template in self.thread_templates:
            pattern = template.get('body_structure', {}).get('pattern', '')
            if style.lower() in pattern.lower():
                return template
        
        return self.thread_templates[0] if self.thread_templates else None


class FlywheelSystem:
    """
    å¤åˆ©ç³»ç»Ÿä¸»ç±»
    æ•´åˆçˆ†æ¬¾æ£€æµ‹ã€æ™ºèƒ½å›å¤ã€å†…å®¹è¾…åŠ©ç­‰åŠŸèƒ½
    """
    
    def __init__(self, output_dir: str = 'output'):
        self.output_dir = output_dir
        self.velocity_detector = VelocityDetector()
        self.reply_generator = SmartReplyGenerator()
        self.content_copilot = ContentCopilot(
            knowledge_dir=os.path.join(output_dir, 'llm_insights')
        )
        self.analysis_db = get_analysis_db_adapter()
        
        # è¿½è¸ªçŠ¶æ€
        self.tracked_tweets = {}  # tweet_id -> last_stats
        
    def process_tweet_update(self, 
                            tweet_id: str,
                            tweet_text: str,
                            author_username: str,
                            current_stats: Dict[str, int],
                            tweet_age_minutes: float) -> Optional[Dict]:
        """
        å¤„ç†æ¨æ–‡æ›´æ–°ï¼Œæ£€æµ‹æ˜¯å¦éœ€è¦æˆªæµ
        
        Args:
            tweet_id: æ¨æ–‡ ID
            tweet_text: æ¨æ–‡å†…å®¹
            author_username: ä½œè€…ç”¨æˆ·å
            current_stats: å½“å‰ç»Ÿè®¡æ•°æ®
            tweet_age_minutes: æ¨æ–‡å‘å¸ƒåçš„åˆ†é’Ÿæ•°
            
        Returns:
            å¦‚æœè§¦å‘æˆªæµï¼Œè¿”å›å›å¤è‰ç¨¿ï¼›å¦åˆ™è¿”å› None
        """
        # è·å–ä¸Šæ¬¡ç»Ÿè®¡æ•°æ®
        previous = self.tracked_tweets.get(tweet_id, {
            'stats': {'likes': 0, 'replies': 0, 'retweets': 0, 'views': 0},
            'timestamp': datetime.now()
        })
        
        previous_stats = previous['stats']
        time_delta = (datetime.now() - previous['timestamp']).total_seconds() / 60
        
        if time_delta < 1:
            return None  # æ›´æ–°é—´éš”å¤ªçŸ­
        
        # è®¡ç®—å¢é€Ÿ
        velocities = self.velocity_detector.calculate_velocity(
            current_stats, previous_stats, time_delta
        )
        
        weighted_velocity = velocities.get('weighted_velocity', 0)
        
        # æ›´æ–°è¿½è¸ªçŠ¶æ€
        self.tracked_tweets[tweet_id] = {
            'stats': current_stats,
            'timestamp': datetime.now()
        }
        
        # æ›´æ–°å†å²å¢é€Ÿ
        self.velocity_detector.update_historical(weighted_velocity)
        
        # æ£€æµ‹æ˜¯å¦æ˜¯çˆ†æ¬¾
        if self.velocity_detector.is_velocity_spike(weighted_velocity):
            logger.info(f"æ£€æµ‹åˆ°æ½œåœ¨çˆ†æ¬¾: {tweet_id}, å¢é€Ÿ: {weighted_velocity:.2f}")
            
            # ç”Ÿæˆå›å¤è‰ç¨¿
            reply_result = self.reply_generator.generate_reply_draft(
                tweet_text=tweet_text,
                tweet_author=author_username,
                tweet_stats=current_stats
            )
            
            if reply_result:
                # ä¿å­˜å€™é€‰
                self.reply_generator.save_candidate(
                    tweet_id=tweet_id,
                    author_username=author_username,
                    detected_signal=f"velocity_spike_{self.velocity_detector.velocity_threshold_percentile}th_percentile",
                    tweet_text=tweet_text,
                    reply_result=reply_result
                )
                
                return {
                    'tweet_id': tweet_id,
                    'author': author_username,
                    'velocity': weighted_velocity,
                    'reply_draft': reply_result
                }
        
        return None
    
    def get_pending_replies(self, limit: int = 20) -> List[Dict]:
        """è·å–å¾…å¤„ç†çš„æˆªæµå›å¤"""
        if not self.analysis_db:
            return []
        return self.analysis_db.get_pending_smart_reply_candidates(limit)
    
    def mark_reply_status(self, candidate_id: int, status: str):
        """æ›´æ–°å›å¤çŠ¶æ€"""
        if not self.analysis_db:
            return
        self.analysis_db.update_smart_reply_status(candidate_id, status)
    
    def get_content_suggestions(self, topic: str) -> Dict:
        """è·å–å†…å®¹åˆ›ä½œå»ºè®®"""
        return self.content_copilot.get_writing_suggestions(topic)
    
    def get_thread_template(self, style: str = 'any') -> Optional[Dict]:
        """è·å– Thread æ¨¡æ¿"""
        return self.content_copilot.get_thread_template(style)


def main():
    """å‘½ä»¤è¡Œå…¥å£ï¼Œæ”¯æŒå®æ—¶æ¨¡å¼å’Œæ‰¹å¤„ç†æ¨¡å¼"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Flywheel System - å¤åˆ©ç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # æ‰¹å¤„ç†æ¨¡å¼ - ç”Ÿæˆå›å¤å€™é€‰ï¼ˆGitHub Actionsï¼‰
  python -m src.flywheel --mode batch --limit 20
  
  # å†…å®¹å»ºè®®ç”Ÿæˆ
  python -m src.flywheel --mode suggest --topic "AIäº§å“è®¾è®¡"
  
  # è·å–Threadæ¨¡æ¿
  python -m src.flywheel --mode template --style educational
  
  # æŸ¥çœ‹å¾…å¤„ç†çš„å›å¤å€™é€‰
  python -m src.flywheel --mode pending
  
  # å®æ—¶æ¨¡å¼ - çˆ†æ¬¾ç›‘æ§ï¼ˆæœ¬åœ°è¿è¡Œï¼Œéœ€è¦å®æ—¶æ•°æ®æµï¼‰
  python -m src.flywheel --mode realtime
        """
    )
    
    parser.add_argument('--mode', type=str, required=True,
                       choices=['batch', 'realtime', 'suggest', 'pending', 'template'],
                       help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--limit', type=int, default=20, help='æ‰¹å¤„ç†æ¨¡å¼ä¸‹çš„å¤„ç†æ•°é‡')
    parser.add_argument('--topic', type=str, help='ä¸»é¢˜ï¼ˆç”¨äº suggestï¼‰')
    parser.add_argument('--style', type=str, default='any', help='æ¨¡æ¿é£æ ¼ï¼ˆç”¨äº templateï¼‰')
    
    args = parser.parse_args()
    
    print("\n" + "=" * 60)
    print(f"Flywheel System - æ¨¡å¼: {args.mode}")
    print("=" * 60)
    
    flywheel = FlywheelSystem()
    
    if args.mode == 'batch':
        # æ‰¹å¤„ç†æ¨¡å¼ï¼šä»å†…å®¹æœºä¼šåˆ—è¡¨ç”Ÿæˆå›å¤å€™é€‰
        logger.info("æ‰¹å¤„ç†æ¨¡å¼ï¼šç”Ÿæˆæ™ºèƒ½å›å¤å€™é€‰")
        from .db_adapter import get_db_adapter
        db = get_db_adapter()
        
        if not db:
            logger.error("æ•°æ®åº“æœªé…ç½®")
            return
        
        # è·å–æœ€è¿‘çš„é«˜äº’åŠ¨æ¨æ–‡
        recent_posts = db.get_all_posts()
        recent_posts['Created At'] = pd.to_datetime(recent_posts['Created At'], errors='coerce')
        cutoff_time = datetime.now() - timedelta(hours=24)
        recent_posts = recent_posts[recent_posts['Created At'] > cutoff_time]
        
        # æŒ‰äº’åŠ¨é‡æ’åº
        recent_posts['engagement'] = (
            recent_posts.get('Favorite Count', 0) + 
            recent_posts.get('Reply Count', 0) * 3 +
            recent_posts.get('Retweet Count', 0) * 2
        )
        top_posts = recent_posts.nlargest(args.limit, 'engagement')
        
        logger.info(f"æ‰¾åˆ° {len(top_posts)} æ¡é«˜äº’åŠ¨æ¨æ–‡")
        
        generated = 0
        all_candidates = []  # æ”¶é›†æ‰€æœ‰å€™é€‰ç”¨äºæœ¬åœ°ä¿å­˜
        
        for _, row in top_posts.iterrows():
            reply_result = flywheel.reply_generator.generate_reply_draft(
                tweet_text=row['Text'],
                tweet_author=row['Author Username'],
                tweet_stats={
                    'views': row.get('View Count', 0),
                    'likes': row.get('Favorite Count', 0),
                    'replies': row.get('Reply Count', 0),
                    'retweets': row.get('Retweet Count', 0)
                }
            )
            
            if reply_result:
                flywheel.reply_generator.save_candidate(
                    tweet_id=row['ID'],
                    author_username=row['Author Username'],
                    detected_signal='batch_high_engagement',
                    tweet_text=row['Text'],
                    reply_result=reply_result
                )
                generated += 1
                
                # æ”¶é›†å€™é€‰æ•°æ®ç”¨äºæœ¬åœ°ä¿å­˜
                all_candidates.append({
                    'tweet_id': str(row['ID']),
                    'author_username': row['Author Username'],
                    'tweet_text': row['Text'][:500],
                    'detected_signal': 'batch_high_engagement',
                    'reply_draft': reply_result.get('reply_draft', ''),
                    'reply_style': reply_result.get('style', ''),
                    'generated_at': reply_result.get('generated_at', datetime.now().isoformat()),
                    'model_used': reply_result.get('model_used', ''),
                    'stats': {
                        'views': int(row.get('View Count', 0) or 0),
                        'likes': int(row.get('Favorite Count', 0) or 0),
                        'replies': int(row.get('Reply Count', 0) or 0),
                        'retweets': int(row.get('Retweet Count', 0) or 0)
                    }
                })
        
        logger.info(f"âœ… ç”Ÿæˆäº† {generated} ä¸ªå›å¤å€™é€‰")
        
        # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
        if all_candidates:
            output_dir = 'output/flywheel'
            os.makedirs(output_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = os.path.join(output_dir, f'smart_reply_candidates_{timestamp}.json')
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'generated_at': datetime.now().isoformat(),
                    'total_candidates': len(all_candidates),
                    'candidates': all_candidates
                }, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ“ æœ¬åœ°æ–‡ä»¶å·²ä¿å­˜: {output_file}")
        
    elif args.mode == 'realtime':
        # å®æ—¶æ¨¡å¼ï¼šæŒç»­ç›‘æ§ï¼ˆæœ¬åœ°ä½¿ç”¨ï¼‰
        logger.info("å®æ—¶æ¨¡å¼ï¼šå¼€å§‹ç›‘æ§çˆ†æ¬¾...")
        logger.warning("æ³¨æ„ï¼šå®æ—¶æ¨¡å¼éœ€è¦æŒç»­çš„æ•°æ®æµè¾“å…¥")
        logger.info("æ­¤æ¨¡å¼é€‚åˆæœ¬åœ°è¿è¡Œï¼Œä¸é€‚åˆ GitHub Actions")
        logger.info("è¯·ä½¿ç”¨å¤–éƒ¨å·¥å…·æ¨é€æ¨æ–‡æ›´æ–°åˆ° process_tweet_update() æ–¹æ³•")
        
    elif args.mode == 'suggest':
        if not args.topic:
            print("âŒ è¯·æä¾› --topic å‚æ•°")
            return
        suggestions = flywheel.get_content_suggestions(args.topic)
        print(json.dumps(suggestions, ensure_ascii=False, indent=2))
        
    elif args.mode == 'pending':
        pending = flywheel.get_pending_replies(limit=args.limit)
        if pending:
            print(f"\nå¾…å¤„ç†çš„æˆªæµå›å¤ ({len(pending)} æ¡):")
            for item in pending:
                print(f"  - [{item['id']}] @{item['author_username']}: {item['tweet_text'][:50]}...")
                print(f"    è‰ç¨¿: {item['draft_reply_text'][:100]}...")
        else:
            print("âœ… æ²¡æœ‰å¾…å¤„ç†çš„æˆªæµå›å¤")
            
    elif args.mode == 'template':
        template = flywheel.get_thread_template(args.style)
        if template:
            print(json.dumps(template, ensure_ascii=False, indent=2))
        else:
            print("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ¨¡æ¿")
    
    print("=" * 60)


if __name__ == '__main__':
    main()
